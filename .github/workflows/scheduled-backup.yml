name: Scheduled Database Backup

on:
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:  # Allow manual trigger
    inputs:
      retention_days:
        description: 'Number of days to retain backups'
        required: false
        default: '30'

env:
  BACKUP_RETENTION_DAYS: ${{ github.event.inputs.retention_days || '30' }}

jobs:
  backup:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          
      - name: Install dependencies
        run: npm ci
        
      - name: Create backup directory
        run: mkdir -p backups
        
      - name: Run database backup
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          NODE_ENV: production
        run: |
          npx tsx scripts/backup/supabase-backup.ts backup
        
      - name: Upload to S3
        uses: jakejarvis/s3-sync-action@master
        with:
          args: --follow-symlinks --exclude '*' --include '*.tar.gz'
        env:
          AWS_S3_BUCKET: ${{ secrets.BACKUP_S3_BUCKET }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: us-east-1
          SOURCE_DIR: 'backups'
          DEST_DIR: 'database-backups'
          
      - name: Clean old backups locally
        run: |
          npx tsx scripts/backup/supabase-backup.ts clean ${{ env.BACKUP_RETENTION_DAYS }}
          
      - name: Clean old S3 backups
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        run: |
          # Install AWS CLI
          pip install awscli
          
          # Delete files older than retention period
          aws s3 ls s3://${{ secrets.BACKUP_S3_BUCKET }}/database-backups/ | \
          while read -r line; do
            createDate=$(echo $line | awk '{print $1" "$2}')
            createDate=$(date -d "$createDate" +%s)
            olderThan=$(date -d "${{ env.BACKUP_RETENTION_DAYS }} days ago" +%s)
            if [[ $createDate -lt $olderThan ]]; then
              fileName=$(echo $line | awk '{print $4}')
              if [[ $fileName != "" ]]; then
                aws s3 rm s3://${{ secrets.BACKUP_S3_BUCKET }}/database-backups/$fileName
                echo "Deleted: $fileName"
              fi
            fi
          done
          
      - name: Notify on success
        if: success() && github.event_name == 'schedule'
        uses: 8398a7/action-slack@v3
        with:
          status: custom
          custom_payload: |
            {
              text: '✅ Database backup completed successfully',
              attachments: [{
                color: 'good',
                fields: [{
                  title: 'Backup Status',
                  value: 'Daily backup completed and uploaded to S3',
                  short: false
                }, {
                  title: 'Timestamp',
                  value: '${{ steps.date.outputs.date }}',
                  short: true
                }]
              }]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
          
      - name: Notify on failure
        if: failure()
        uses: 8398a7/action-slack@v3
        with:
          status: failure
          text: '❌ Database backup failed! Immediate attention required.'
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

  verify-backup:
    needs: backup
    runs-on: ubuntu-latest
    if: success()
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Verify latest backup exists
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        run: |
          # Install AWS CLI
          pip install awscli
          
          # Check if backup from today exists
          TODAY=$(date +%Y-%m-%d)
          BACKUP_EXISTS=$(aws s3 ls s3://${{ secrets.BACKUP_S3_BUCKET }}/database-backups/ | grep "backup-$TODAY" | wc -l)
          
          if [ $BACKUP_EXISTS -eq 0 ]; then
            echo "❌ No backup found for today!"
            exit 1
          else
            echo "✅ Backup verified for $TODAY"
          fi