/**
 * Real-Time Analytics Pipeline
 * Processes millions of sustainability data points in real-time
 * Feeds the Advanced Analytics Engine for autonomous intelligence
 */

// import { createClient } from '@/lib/supabase/server';
const createClient = () => ({ from: () => ({ insert: () => Promise.resolve({ error: null }) }) });
import { analyticsEngine, AnalyticsDataPoint } from './analytics-engine';
import { EventEmitter } from 'events';

export interface StreamProcessor {
  id: string;
  name: string;
  type: 'transformer' | 'validator' | 'enricher' | 'aggregator' | 'forwarder';
  config: Record<string, any>;
  isEnabled: boolean;
  metrics: {
    processed: number;
    errors: number;
    averageLatency: number;
    throughput: number; // items per second
  };
}

export interface DataStream {
  id: string;
  organizationId: string;
  source: 'sensor' | 'api' | 'manual' | 'integration' | 'calculation' | 'prediction';
  dataType: string;
  frequency: 'realtime' | '1min' | '5min' | '15min' | '1hour';
  processors: StreamProcessor[];
  isActive: boolean;
  buffer: AnalyticsDataPoint[];
  lastProcessed: Date;
}

export interface PipelineMetrics {
  totalDataPoints: number;
  processingRate: number; // points per second
  errorRate: number;
  averageLatency: number;
  activeStreams: number;
  bufferSize: number;
  memoryUsage: number;
}

export interface DataQualityCheck {
  rule: string;
  severity: 'warning' | 'error' | 'critical';
  description: string;
  action: 'log' | 'reject' | 'correct' | 'flag';
}

export class RealTimeAnalyticsPipeline extends EventEmitter {
  private supabase: any;
  private streams: Map<string, DataStream> = new Map();
  private processors: Map<string, StreamProcessor> = new Map();
  private isRunning: boolean = false;
  private metrics: PipelineMetrics;
  private qualityRules: DataQualityCheck[] = [];

  constructor() {
    super();
    this.supabase = createClient();
    this.metrics = {
      totalDataPoints: 0,
      processingRate: 0,
      errorRate: 0,
      averageLatency: 0,
      activeStreams: 0,
      bufferSize: 0,
      memoryUsage: 0
    };
    this.initializePipeline();
  }

  private async initializePipeline() {
    console.log('üöÄ Initializing Real-Time Analytics Pipeline...');
    
    // Load existing streams and processors
    await this.loadDataStreams();
    await this.loadStreamProcessors();
    await this.loadQualityRules();
    
    // Set up monitoring
    this.setupMetricsCollection();
    
    // Start the pipeline
    this.start();
    
    console.log('‚úÖ Real-Time Analytics Pipeline ready for millions of data points!');
  }

  /**
   * Pipeline Control
   */
  public start(): void {
    if (this.isRunning) return;
    
    this.isRunning = true;
    
    // Start stream processors
    this.startStreamProcessors();
    
    // Start metrics collection
    this.startMetricsCollection();
    
    // Start buffer processing
    this.startBufferProcessing();
    
    console.log('‚ö° Real-time analytics pipeline STARTED');
    this.emit('pipelineStarted');
  }

  public stop(): void {
    if (!this.isRunning) return;
    
    this.isRunning = false;
    console.log('‚èπÔ∏è Real-time analytics pipeline STOPPED');
    this.emit('pipelineStopped');
  }

  /**
   * Data Ingestion
   */
  public async ingest(dataPoints: AnalyticsDataPoint[]): Promise<{
    accepted: number;
    rejected: number;
    errors: string[];
  }> {
    const results = {
      accepted: 0,
      rejected: 0,
      errors: [] as string[]
    };

    try {
      for (const dataPoint of dataPoints) {
        const validationResult = await this.validateDataPoint(dataPoint);
        
        if (validationResult.valid) {
          await this.routeDataPoint(dataPoint);
          results.accepted++;
        } else {
          results.rejected++;
          results.errors.push(`${dataPoint.id}: ${validationResult.errors.join(', ')}`);
        }
      }

      // Update metrics
      this.metrics.totalDataPoints += results.accepted;
      this.updateProcessingRate(results.accepted);

      return results;
    } catch (error) {
      console.error('Data ingestion error:', error);
      throw error;
    }
  }

  public async ingestSingle(dataPoint: AnalyticsDataPoint): Promise<boolean> {
    try {
      const validationResult = await this.validateDataPoint(dataPoint);
      
      if (validationResult.valid) {
        await this.routeDataPoint(dataPoint);
        this.metrics.totalDataPoints++;
        return true;
      } else {
        console.warn(`Data point rejected: ${validationResult.errors.join(', ')}`);
        return false;
      }
    } catch (error) {
      console.error('Single data point ingestion error:', error);
      return false;
    }
  }

  /**
   * Data Validation
   */
  private async validateDataPoint(dataPoint: AnalyticsDataPoint): Promise<{
    valid: boolean;
    errors: string[];
    warnings: string[];
  }> {
    const errors: string[] = [];
    const warnings: string[] = [];

    try {
      // Basic structure validation
      if (!dataPoint.id) errors.push('Missing ID');
      if (!dataPoint.organizationId) errors.push('Missing organization ID');
      if (!dataPoint.timestamp) errors.push('Missing timestamp');
      if (!dataPoint.type) errors.push('Missing data type');
      if (typeof dataPoint.value !== 'number') errors.push('Invalid value type');
      if (!dataPoint.unit) errors.push('Missing unit');
      if (!dataPoint.source) errors.push('Missing source');

      // Timestamp validation
      const timestamp = new Date(dataPoint.timestamp);
      const now = new Date();
      const futureLimit = new Date(now.getTime() + 24 * 60 * 60 * 1000); // 24 hours
      const pastLimit = new Date(now.getTime() - 7 * 24 * 60 * 60 * 1000); // 7 days

      if (timestamp > futureLimit) {
        errors.push('Timestamp too far in the future');
      } else if (timestamp < pastLimit) {
        warnings.push('Timestamp older than 7 days');
      }

      // Value range validation
      const valueValidation = this.validateValueRange(dataPoint);
      errors.push(...valueValidation.errors);
      warnings.push(...valueValidation.warnings);

      // Data quality rules
      for (const rule of this.qualityRules) {
        const ruleResult = await this.applyQualityRule(dataPoint, rule);
        if (!ruleResult.passed) {
          if (rule.severity === 'error' || rule.severity === 'critical') {
            errors.push(`Quality rule failed: ${rule.description}`);
          } else {
            warnings.push(`Quality rule warning: ${rule.description}`);
          }
        }
      }

      return {
        valid: errors.length === 0,
        errors,
        warnings
      };
    } catch (error) {
      console.error('Data validation error:', error);
      return {
        valid: false,
        errors: ['Validation system error'],
        warnings: []
      };
    }
  }

  private validateValueRange(dataPoint: AnalyticsDataPoint): {
    errors: string[];
    warnings: string[];
  } {
    const errors: string[] = [];
    const warnings: string[] = [];

    // Define reasonable ranges for different data types
    const ranges: Record<string, { min: number; max: number; warningThreshold: number }> = {
      'energy': { min: 0, max: 100000, warningThreshold: 50000 }, // kWh
      'water': { min: 0, max: 10000, warningThreshold: 5000 }, // Liters
      'waste': { min: 0, max: 1000, warningThreshold: 500 }, // kg
      'emissions': { min: 0, max: 50000, warningThreshold: 25000 }, // kg CO2e
      'temperature': { min: -50, max: 70, warningThreshold: 50 }, // Celsius
      'occupancy': { min: 0, max: 10000, warningThreshold: 5000 }, // People
      'air_quality': { min: 0, max: 500, warningThreshold: 300 } // AQI
    };

    const range = ranges[dataPoint.type];
    if (range) {
      if (dataPoint.value < range.min || dataPoint.value > range.max) {
        errors.push(`Value ${dataPoint.value} out of valid range [${range.min}, ${range.max}]`);
      } else if (dataPoint.value > range.warningThreshold) {
        warnings.push(`Value ${dataPoint.value} exceeds warning threshold ${range.warningThreshold}`);
      }
    }

    // Check for impossible values
    if (!isFinite(dataPoint.value) || isNaN(dataPoint.value)) {
      errors.push('Value is not a finite number');
    }

    if (dataPoint.value < 0 && !['temperature'].includes(dataPoint.type)) {
      errors.push('Negative value not allowed for this data type');
    }

    return { errors, warnings };
  }

  /**
   * Data Routing
   */
  private async routeDataPoint(dataPoint: AnalyticsDataPoint): Promise<void> {
    try {
      // Find relevant streams for this data point
      const relevantStreams = Array.from(this.streams.values()).filter(
        stream => 
          stream.organizationId === dataPoint.organizationId &&
          (stream.dataType === dataPoint.type || stream.dataType === '*') &&
          stream.isActive
      );

      if (relevantStreams.length === 0) {
        // Create default stream if none exists
        const defaultStream = await this.createDefaultStream(dataPoint);
        relevantStreams.push(defaultStream);
      }

      // Add data point to stream buffers
      for (const stream of relevantStreams) {
        stream.buffer.push(dataPoint);
        
        // Process immediately if buffer is full or for real-time streams
        if (stream.frequency === 'realtime' || stream.buffer.length >= this.getBufferLimit(stream.frequency)) {
          await this.processStreamBuffer(stream);
        }
      }
    } catch (error) {
      console.error('Data routing error:', error);
      throw error;
    }
  }

  private async createDefaultStream(dataPoint: AnalyticsDataPoint): Promise<DataStream> {
    const stream: DataStream = {
      id: crypto.randomUUID(),
      organizationId: dataPoint.organizationId,
      source: dataPoint.source,
      dataType: dataPoint.type,
      frequency: 'realtime',
      processors: await this.getDefaultProcessors(),
      isActive: true,
      buffer: [],
      lastProcessed: new Date()
    };

    this.streams.set(stream.id, stream);

    // Store in database
    await this.supabase
      .from('analytics_streams')
      .insert({
        id: stream.id,
        organization_id: stream.organizationId,
        source: stream.source,
        data_type: stream.dataType,
        frequency: stream.frequency,
        processors: stream.processors.map(p => p.id),
        is_active: stream.isActive,
        created_at: new Date().toISOString()
      });

    console.log(`üì° Created default stream for ${dataPoint.type} data`);
    return stream;
  }

  /**
   * Stream Processing
   */
  private async processStreamBuffer(stream: DataStream): Promise<void> {
    if (stream.buffer.length === 0) return;

    const startTime = Date.now();
    const batchSize = stream.buffer.length;

    try {
      // Create a copy of the buffer and clear it
      const dataPoints = [...stream.buffer];
      stream.buffer = [];

      // Process through each processor in sequence
      let processedData = dataPoints;
      
      for (const processor of stream.processors.filter(p => p.isEnabled).sort((a, b) => {
        // Process in order: validator -> transformer -> enricher -> aggregator -> forwarder
        const order = ['validator', 'transformer', 'enricher', 'aggregator', 'forwarder'];
        return order.indexOf(a.type) - order.indexOf(b.type);
      })) {
        const processorStartTime = Date.now();
        
        try {
          processedData = await this.runStreamProcessor(processor, processedData, stream);
          
          // Update processor metrics
          const processorLatency = Date.now() - processorStartTime;
          processor.metrics.processed += processedData.length;
          processor.metrics.averageLatency = (processor.metrics.averageLatency + processorLatency) / 2;
          processor.metrics.throughput = processedData.length / (processorLatency / 1000);
        } catch (error) {
          console.error(`Stream processor ${processor.name} error:`, error);
          processor.metrics.errors++;
        }
      }

      // Forward processed data to analytics engine
      for (const dataPoint of processedData) {
        await analyticsEngine.ingestDataPoint(dataPoint);
      }

      // Update stream metrics
      const totalLatency = Date.now() - startTime;
      stream.lastProcessed = new Date();
      
      console.log(`üìä Processed ${batchSize} data points in ${totalLatency}ms (${stream.dataType} stream)`);
      
      this.emit('streamProcessed', {
        streamId: stream.id,
        dataType: stream.dataType,
        processed: batchSize,
        latency: totalLatency
      });
    } catch (error) {
      console.error('Stream buffer processing error:', error);
      
      // Re-add data points to buffer if processing failed
      stream.buffer.unshift(...stream.buffer);
    }
  }

  private async runStreamProcessor(
    processor: StreamProcessor,
    dataPoints: AnalyticsDataPoint[],
    stream: DataStream
  ): Promise<AnalyticsDataPoint[]> {
    switch (processor.type) {
      case 'validator':
        return await this.runValidator(processor, dataPoints);
      case 'transformer':
        return await this.runTransformer(processor, dataPoints);
      case 'enricher':
        return await this.runEnricher(processor, dataPoints, stream);
      case 'aggregator':
        return await this.runAggregator(processor, dataPoints);
      case 'forwarder':
        return await this.runForwarder(processor, dataPoints);
      default:
        console.warn(`Unknown processor type: ${processor.type}`);
        return dataPoints;
    }
  }

  private async runValidator(
    processor: StreamProcessor,
    dataPoints: AnalyticsDataPoint[]
  ): Promise<AnalyticsDataPoint[]> {
    const validDataPoints: AnalyticsDataPoint[] = [];
    
    for (const dataPoint of dataPoints) {
      const validation = await this.validateDataPoint(dataPoint);
      if (validation.valid) {
        validDataPoints.push(dataPoint);
      } else {
        console.warn(`Validation failed for data point ${dataPoint.id}: ${validation.errors.join(', ')}`);
      }
    }
    
    return validDataPoints;
  }

  private async runTransformer(
    processor: StreamProcessor,
    dataPoints: AnalyticsDataPoint[]
  ): Promise<AnalyticsDataPoint[]> {
    const transformedPoints: AnalyticsDataPoint[] = [];
    
    for (const dataPoint of dataPoints) {
      const transformed = await this.applyTransformations(dataPoint, processor.config);
      transformedPoints.push(transformed);
    }
    
    return transformedPoints;
  }

  private async runEnricher(
    processor: StreamProcessor,
    dataPoints: AnalyticsDataPoint[],
    stream: DataStream
  ): Promise<AnalyticsDataPoint[]> {
    const enrichedPoints: AnalyticsDataPoint[] = [];
    
    for (const dataPoint of dataPoints) {
      const enriched = await this.enrichDataPoint(dataPoint, stream);
      enrichedPoints.push(enriched);
    }
    
    return enrichedPoints;
  }

  private async runAggregator(
    processor: StreamProcessor,
    dataPoints: AnalyticsDataPoint[]
  ): Promise<AnalyticsDataPoint[]> {
    // Aggregate data points based on configuration
    const aggregated = await this.aggregateDataPoints(dataPoints, processor.config);
    return aggregated;
  }

  private async runForwarder(
    processor: StreamProcessor,
    dataPoints: AnalyticsDataPoint[]
  ): Promise<AnalyticsDataPoint[]> {
    // Forward to external systems if configured
    if (processor.config.forwardTo) {
      await this.forwardDataPoints(dataPoints, processor.config.forwardTo);
    }
    
    return dataPoints;
  }

  /**
   * Data Transformation and Enrichment
   */
  private async applyTransformations(
    dataPoint: AnalyticsDataPoint,
    config: Record<string, any>
  ): Promise<AnalyticsDataPoint> {
    let transformed = { ...dataPoint };

    // Unit conversion
    if (config.unitConversion) {
      transformed.value = this.convertUnits(
        transformed.value,
        transformed.unit,
        config.unitConversion.targetUnit
      );
      transformed.unit = config.unitConversion.targetUnit;
    }

    // Scale factor
    if (config.scaleFactor) {
      transformed.value *= config.scaleFactor;
    }

    // Rounding
    if (config.decimalPlaces !== undefined) {
      transformed.value = Math.round(transformed.value * Math.pow(10, config.decimalPlaces)) / Math.pow(10, config.decimalPlaces);
    }

    // Add transformation metadata
    transformed.metadata = {
      ...transformed.metadata,
      transformed: true,
      transformedAt: new Date().toISOString(),
      originalValue: dataPoint.value,
      originalUnit: dataPoint.unit
    };

    return transformed;
  }

  private async enrichDataPoint(
    dataPoint: AnalyticsDataPoint,
    stream: DataStream
  ): Promise<AnalyticsDataPoint> {
    const enriched = { ...dataPoint };

    try {
      // Add building context
      if (dataPoint.buildingId) {
        const { data: building } = await this.supabase
          .from('buildings')
          .select('name, type, size, location')
          .eq('id', dataPoint.buildingId)
          .single();

        if (building) {
          enriched.metadata = {
            ...enriched.metadata,
            building: building
          };
        }
      }

      // Add weather context for relevant data types
      if (['energy', 'temperature', 'emissions'].includes(dataPoint.type)) {
        const weather = await this.getWeatherContext(dataPoint.timestamp, enriched.metadata?.building?.location);
        if (weather) {
          enriched.metadata = {
            ...enriched.metadata,
            weather: weather
          };
        }
      }

      // Add time-based context
      const timestamp = new Date(dataPoint.timestamp);
      enriched.metadata = {
        ...enriched.metadata,
        timeContext: {
          hour: timestamp.getHours(),
          dayOfWeek: timestamp.getDay(),
          month: timestamp.getMonth(),
          quarter: Math.floor(timestamp.getMonth() / 3) + 1,
          isWeekend: timestamp.getDay() === 0 || timestamp.getDay() === 6,
          isBusinessHours: timestamp.getHours() >= 9 && timestamp.getHours() <= 17
        }
      };

      // Calculate derived metrics
      enriched.metadata = {
        ...enriched.metadata,
        derived: await this.calculateDerivedMetrics(dataPoint)
      };

    } catch (error) {
      console.error('Data enrichment error:', error);
      // Return original data point if enrichment fails
    }

    return enriched;
  }

  /**
   * Utility Functions
   */
  private convertUnits(value: number, fromUnit: string, toUnit: string): number {
    // Unit conversion logic
    const conversions: Record<string, Record<string, number | ((c: number) => number)>> = {
      'kWh': { 'Wh': 1000, 'MWh': 0.001 },
      'L': { 'mL': 1000, 'gal': 0.264172 },
      'kg': { 'g': 1000, 'lb': 2.20462 },
      'C': { 'F': (c: number) => c * 9/5 + 32, 'K': (c: number) => c + 273.15 }
    };

    if (conversions[fromUnit] && conversions[fromUnit][toUnit]) {
      const factor = conversions[fromUnit][toUnit];
      return typeof factor === 'function' ? factor(value) : value * (factor as number);
    }

    return value; // No conversion available
  }

  private async getWeatherContext(timestamp: Date, location?: any): Promise<any> {
    if (!location) return null;

    try {
      // Mock weather data - in production, this would call weather API
      return {
        temperature: 22,
        humidity: 65,
        condition: 'clear',
        windSpeed: 10
      };
    } catch (error) {
      console.error('Weather context error:', error);
      return null;
    }
  }

  private async calculateDerivedMetrics(dataPoint: AnalyticsDataPoint): Promise<any> {
    const derived: any = {};

    // Carbon intensity calculation
    if (dataPoint.type === 'energy') {
      derived.carbonEmissions = dataPoint.value * 0.4; // kg CO2e per kWh (average grid)
    }

    // Efficiency metrics
    if (dataPoint.buildingId && dataPoint.metadata?.building?.size) {
      derived.intensityPerSqM = dataPoint.value / dataPoint.metadata.building.size;
    }

    // Cost estimation
    derived.estimatedCost = this.estimateCost(dataPoint);

    return derived;
  }

  private estimateCost(dataPoint: AnalyticsDataPoint): number {
    const costFactors: Record<string, number> = {
      'energy': 0.12, // USD per kWh
      'water': 0.004, // USD per liter
      'waste': 0.15, // USD per kg
      'emissions': 0.05 // USD per kg CO2e (carbon pricing)
    };

    const factor = costFactors[dataPoint.type] || 0;
    return dataPoint.value * factor;
  }

  private getBufferLimit(frequency: string): number {
    const limits: Record<string, number> = {
      'realtime': 1,
      '1min': 60,
      '5min': 300,
      '15min': 900,
      '1hour': 3600
    };
    return limits[frequency] || 100;
  }

  private async aggregateDataPoints(
    dataPoints: AnalyticsDataPoint[],
    config: Record<string, any>
  ): Promise<AnalyticsDataPoint[]> {
    if (dataPoints.length <= 1) return dataPoints;

    const aggregated: AnalyticsDataPoint = {
      id: crypto.randomUUID(),
      organizationId: dataPoints[0].organizationId,
      buildingId: dataPoints[0].buildingId,
      timestamp: new Date(),
      type: dataPoints[0].type,
      value: 0,
      unit: dataPoints[0].unit,
      source: 'calculation' as const,
      metadata: {
        aggregated: true,
        aggregatedFrom: dataPoints.length,
        aggregationType: config.type || 'sum'
      }
    };

    // Perform aggregation based on type
    switch (config.type) {
      case 'sum':
        aggregated.value = dataPoints.reduce((sum, point) => sum + point.value, 0);
        break;
      case 'average':
        aggregated.value = dataPoints.reduce((sum, point) => sum + point.value, 0) / dataPoints.length;
        break;
      case 'min':
        aggregated.value = Math.min(...dataPoints.map(p => p.value));
        break;
      case 'max':
        aggregated.value = Math.max(...dataPoints.map(p => p.value));
        break;
      default:
        aggregated.value = dataPoints[dataPoints.length - 1].value; // Latest value
    }

    return [aggregated];
  }

  private async forwardDataPoints(dataPoints: AnalyticsDataPoint[], destination: string): Promise<void> {
    try {
      // Forward to external system (webhook, API, etc.)
      console.log(`üì§ Forwarding ${dataPoints.length} data points to ${destination}`);
      // Implementation would depend on destination type
    } catch (error) {
      console.error('Data forwarding error:', error);
    }
  }

  /**
   * Quality Rules and Monitoring
   */
  private async applyQualityRule(
    dataPoint: AnalyticsDataPoint,
    rule: DataQualityCheck
  ): Promise<{ passed: boolean; message?: string }> {
    try {
      // Apply quality rule logic based on rule type
      switch (rule.rule) {
        case 'duplicate_check':
          return await this.checkForDuplicates(dataPoint);
        case 'completeness':
          return this.checkCompleteness(dataPoint);
        case 'consistency':
          return await this.checkConsistency(dataPoint);
        case 'accuracy':
          return await this.checkAccuracy(dataPoint);
        default:
          return { passed: true };
      }
    } catch (error) {
      console.error('Quality rule application error:', error);
      return { passed: false, message: 'Quality rule system error' };
    }
  }

  private async checkForDuplicates(dataPoint: AnalyticsDataPoint): Promise<{ passed: boolean; message?: string }> {
    const { data: existing } = await this.supabase
      .from('analytics_data_points')
      .select('id')
      .eq('organization_id', dataPoint.organizationId)
      .eq('building_id', dataPoint.buildingId)
      .eq('type', dataPoint.type)
      .eq('timestamp', dataPoint.timestamp.toISOString())
      .eq('value', dataPoint.value)
      .limit(1);

    return {
      passed: !existing || existing.length === 0,
      message: existing && existing.length > 0 ? 'Duplicate data point detected' : undefined
    };
  }

  private checkCompleteness(dataPoint: AnalyticsDataPoint): { passed: boolean; message?: string } {
    const requiredFields = ['id', 'organizationId', 'timestamp', 'type', 'value', 'unit', 'source'];
    const missingFields = requiredFields.filter(field => !dataPoint[field as keyof AnalyticsDataPoint]);

    return {
      passed: missingFields.length === 0,
      message: missingFields.length > 0 ? `Missing required fields: ${missingFields.join(', ')}` : undefined
    };
  }

  private async checkConsistency(dataPoint: AnalyticsDataPoint): Promise<{ passed: boolean; message?: string }> {
    // Check consistency with recent data points
    const { data: recentPoints } = await this.supabase
      .from('analytics_data_points')
      .select('value')
      .eq('organization_id', dataPoint.organizationId)
      .eq('type', dataPoint.type)
      .gte('timestamp', new Date(dataPoint.timestamp.getTime() - 60 * 60 * 1000).toISOString())
      .order('timestamp', { ascending: false })
      .limit(10);

    if (!recentPoints || recentPoints.length === 0) {
      return { passed: true }; // No recent data to compare
    }

    const recentValues = recentPoints.map(p => p.value);
    const average = recentValues.reduce((a, b) => a + b, 0) / recentValues.length;
    const deviation = Math.abs(dataPoint.value - average) / average;

    return {
      passed: deviation < 2.0, // Allow up to 200% deviation
      message: deviation >= 2.0 ? `Value deviates significantly from recent average (${(deviation * 100).toFixed(1)}%)` : undefined
    };
  }

  private async checkAccuracy(dataPoint: AnalyticsDataPoint): Promise<{ passed: boolean; message?: string }> {
    // Accuracy checks based on external validation or sensor calibration
    // This would integrate with sensor management systems
    return { passed: true }; // Placeholder
  }

  /**
   * Setup and Configuration
   */
  private async loadDataStreams(): Promise<void> {
    try {
      const { data: streams } = await this.supabase
        .from('analytics_streams')
        .select('*')
        .eq('is_active', true);

      if (streams) {
        for (const streamData of streams) {
          const processors = await this.loadProcessorsForStream(streamData.processors || []);
          
          const stream: DataStream = {
            id: streamData.id,
            organizationId: streamData.organization_id,
            source: streamData.source,
            dataType: streamData.data_type,
            frequency: streamData.frequency,
            processors,
            isActive: streamData.is_active,
            buffer: [],
            lastProcessed: new Date(streamData.last_processed || Date.now())
          };

          this.streams.set(stream.id, stream);
        }
      }

      console.log(`üì° Loaded ${this.streams.size} data streams`);
    } catch (error) {
      console.error('Failed to load data streams:', error);
    }
  }

  private async loadStreamProcessors(): Promise<void> {
    try {
      const { data: processors } = await this.supabase
        .from('stream_processors')
        .select('*')
        .eq('is_enabled', true);

      if (processors) {
        processors.forEach(processorData => {
          const processor: StreamProcessor = {
            id: processorData.id,
            name: processorData.name,
            type: processorData.type,
            config: processorData.config || {},
            isEnabled: processorData.is_enabled,
            metrics: {
              processed: 0,
              errors: 0,
              averageLatency: 0,
              throughput: 0
            }
          };

          this.processors.set(processor.id, processor);
        });
      }

      console.log(`üîß Loaded ${this.processors.size} stream processors`);
    } catch (error) {
      console.error('Failed to load stream processors:', error);
    }
  }

  private async loadProcessorsForStream(processorIds: string[]): Promise<StreamProcessor[]> {
    const processors: StreamProcessor[] = [];

    for (const id of processorIds) {
      const processor = this.processors.get(id);
      if (processor) {
        processors.push(processor);
      }
    }

    return processors;
  }

  private async loadQualityRules(): Promise<void> {
    // Load data quality rules
    this.qualityRules = [
      {
        rule: 'duplicate_check',
        severity: 'warning',
        description: 'Check for duplicate data points',
        action: 'log'
      },
      {
        rule: 'completeness',
        severity: 'error',
        description: 'Ensure all required fields are present',
        action: 'reject'
      },
      {
        rule: 'consistency',
        severity: 'warning',
        description: 'Check consistency with recent data',
        action: 'flag'
      }
    ];

    console.log(`‚úÖ Loaded ${this.qualityRules.length} data quality rules`);
  }

  private async getDefaultProcessors(): Promise<StreamProcessor[]> {
    return [
      {
        id: 'default-validator',
        name: 'Default Validator',
        type: 'validator',
        config: { strict: false },
        isEnabled: true,
        metrics: { processed: 0, errors: 0, averageLatency: 0, throughput: 0 }
      },
      {
        id: 'default-enricher',
        name: 'Default Enricher',
        type: 'enricher',
        config: { addContext: true },
        isEnabled: true,
        metrics: { processed: 0, errors: 0, averageLatency: 0, throughput: 0 }
      }
    ];
  }

  /**
   * Monitoring and Metrics
   */
  private setupMetricsCollection(): void {
    // Collect metrics every 30 seconds
    setInterval(() => {
      this.updateMetrics();
    }, 30000);
  }

  private startStreamProcessors(): void {
    // Process stream buffers every 5 seconds
    setInterval(() => {
      if (this.isRunning) {
        this.processAllStreamBuffers();
      }
    }, 5000);
  }

  private startMetricsCollection(): void {
    // Detailed metrics collection every minute
    setInterval(() => {
      if (this.isRunning) {
        this.collectDetailedMetrics();
      }
    }, 60000);
  }

  private startBufferProcessing(): void {
    // Process buffers based on frequency
    setInterval(() => {
      if (this.isRunning) {
        this.processScheduledBuffers();
      }
    }, 60000); // Check every minute
  }

  private async processAllStreamBuffers(): Promise<void> {
    for (const stream of Array.from(this.streams.values())) {
      if (stream.isActive && stream.buffer.length > 0) {
        await this.processStreamBuffer(stream);
      }
    }
  }

  private async processScheduledBuffers(): Promise<void> {
    const now = new Date();

    for (const stream of Array.from(this.streams.values())) {
      if (!stream.isActive || stream.buffer.length === 0) continue;

      const timeSinceLastProcess = now.getTime() - stream.lastProcessed.getTime();
      const shouldProcess = this.shouldProcessBuffer(stream, timeSinceLastProcess);

      if (shouldProcess) {
        await this.processStreamBuffer(stream);
      }
    }
  }

  private shouldProcessBuffer(stream: DataStream, timeSinceLastProcess: number): boolean {
    const intervals: Record<string, number> = {
      'realtime': 5000, // 5 seconds
      '1min': 60000, // 1 minute
      '5min': 300000, // 5 minutes
      '15min': 900000, // 15 minutes
      '1hour': 3600000 // 1 hour
    };

    const interval = intervals[stream.frequency] || 60000;
    return timeSinceLastProcess >= interval;
  }

  private updateMetrics(): void {
    this.metrics.activeStreams = Array.from(this.streams.values()).filter(s => s.isActive).length;
    this.metrics.bufferSize = Array.from(this.streams.values()).reduce((total, stream) => total + stream.buffer.length, 0);
    this.metrics.memoryUsage = process.memoryUsage().heapUsed / 1024 / 1024; // MB

    // Emit metrics update
    this.emit('metricsUpdated', this.metrics);
  }

  private updateProcessingRate(processed: number): void {
    const now = Date.now();
    const timeWindow = 60000; // 1 minute
    
    // Simple rate calculation (would be more sophisticated in production)
    this.metrics.processingRate = processed / (timeWindow / 1000);
  }

  private collectDetailedMetrics(): void {
    console.log('üìä Pipeline Metrics:', {
      totalDataPoints: this.metrics.totalDataPoints,
      processingRate: `${this.metrics.processingRate.toFixed(2)} points/sec`,
      activeStreams: this.metrics.activeStreams,
      bufferSize: this.metrics.bufferSize,
      memoryUsage: `${this.metrics.memoryUsage.toFixed(2)} MB`
    });
  }

  /**
   * Public API
   */
  public getMetrics(): PipelineMetrics {
    return { ...this.metrics };
  }

  public getStreams(): DataStream[] {
    return Array.from(this.streams.values());
  }

  public getProcessors(): StreamProcessor[] {
    return Array.from(this.processors.values());
  }

  public async createStream(streamConfig: Partial<DataStream>): Promise<string> {
    const stream: DataStream = {
      id: crypto.randomUUID(),
      organizationId: streamConfig.organizationId!,
      source: streamConfig.source || 'api',
      dataType: streamConfig.dataType!,
      frequency: streamConfig.frequency || 'realtime',
      processors: streamConfig.processors || await this.getDefaultProcessors(),
      isActive: true,
      buffer: [],
      lastProcessed: new Date()
    };

    this.streams.set(stream.id, stream);
    return stream.id;
  }

  public async deleteStream(streamId: string): Promise<boolean> {
    const stream = this.streams.get(streamId);
    if (stream) {
      stream.isActive = false;
      this.streams.delete(streamId);
      return true;
    }
    return false;
  }
}

// Export singleton instance
export const realTimePipeline = new RealTimeAnalyticsPipeline();